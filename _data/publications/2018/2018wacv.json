{
    "id": "2018wacv_hico",
    "authors": "Liyue Shen,  Serena Yeung, Judy Hoffman,  Greg Mori,  Li Fei-Fei",
    "title": "Scaling Human-Object Interaction Recognition through Zero-Shot Learning",
    "venue": "wacv",
    "year": "2018",
    "pdf": "http://vision.stanford.edu/pdf/shen2018wacv.pdf",
    "slides": "",
    "code": "",
    "bibtex_type": "inproceedings",
    "fig": "figs/2018_wacv.png",
    "project": "",
    "is_new": false,
	"special": "",
    "abstract": "Recognizing human object interactions (HOI) is an important part of distinguishing the rich variety of human action in the visual world. While recent progress has been made in improving HOI recognition in the fully supervised setting, the space of possible human-object interactions is large and it is impractical to obtain labeled training data for all interactions of interest. In this work, we tackle the challenge of scaling HOI recognition to the long tail of categories through a zero-shot learning approach. We introduce a factorized model for HOI detection that disentangles reasoning on verbs and objects, and at test-time can therefore produce detections for novel verb-object pairs. We present experiments on the recently introduced large-scale HICODET dataset, and show that our model is able to both perform comparably to state-of-the-art in fully-supervised HOI detection, while simultaneously achieving effective zeroshot detection of new HOI categories."
}
