{
    "id": "2014nipsHoffman",
    "authors": "Judy Hoffman,  Sergio Guadarrama,  Eric Tzeng,  Ronghang Hu,  Jeff Donahue,  Ross Girshick,  Trevor Darrell,  Kate Saenko",
    "title": "LSDA: Large Scale Detection through Adaptation",
    "venue": "nips",
    "year": "2014",
    "pdf": "https://arxiv.org/abs/1407.5035",
    "slides": "https://drive.google.com/open?id=0B0abnIslIG1nVWE0ZjRvYzZFa0E",
    "code": "",
    "bibtex_type": "inproceedings",
    "fig": "figs/2014nipsHoffman.png",
    "project": "http://lsda.berkeleyvision.org/",
    "is_new": false,
	"special": "",
    "abstract": "A major challenge in scaling object detection is the difficulty of obtaining labeled images for large numbers of categories. Recently, deep convolutional neural networks (CNNs) have emerged as clear winners on object classification benchmarks, in part due to training with 1.2M+ labeled classification images. Unfortunately, only a small fraction of those labels are available for the detection task. It is much cheaper and easier to collect large quantities of image-level labels from search engines than it is to collect detection data and label it with precise bounding boxes. In this paper, we propose Large Scale Detection through Adaptation (LSDA), an algorithm which learns the difference between the two tasks and transfers this knowledge to classifiers for categories without bounding box annotated data, turning them into detectors. Our method has the potential to enable detection for the tens of thousands of categories that lack bounding box annotations, yet have plenty of classification data. Evaluation on the ImageNet LSVRC-2013 detection challenge demonstrates the efficacy of our approach. This algorithm enables us to produce a >7.6K detector by using available classification data from leaf nodes in the ImageNet tree. We additionally demonstrate how to modify our architecture to produce a fast detector (running at 2fps for the 7.6K detector)."
}