{
    "id": "2020EccvWLikelihood",
    "authors": "Fu Lin, Rohit Mittapali, Prithvijit Chattopadhyay, Daniel Bolya, Judy Hoffman",
    "title": "Likelihood Landscapes: A Unifying Principle Behind Many Adversarial Defenses",
    "venue": "eccv-arow",
    "year": "2020",
    "pdf": "https://arxiv.org/abs/2008.11300",
    "slides": "",
    "code": "",
    "bibtex_type": "inproceedings",
    "fig": "figs/2020EccvWLikelihood.png",
    "project": "",
    "video": "",
    "is_new": false,
	"special": "Best paper runner up",
    "abstract": "Convolutional Neural Networks (CNNs) have been shown to be vulnerable to adversarial examples, which are known to locate in subspaces close to where normal data lies but are not naturally occurring and have low probability. In this work, we investigate the potential effect defense techniques have on the geometry of the likelihood landscape - likelihood of the input images under the trained model. We first propose a way to visualize the likelihood landscape by leveraging an energy-based model interpretation of discriminative classifiers. Then we introduce a measure to quantify the flatness of the likelihood landscape. We observe that a subset of adversarial defense techniques results in a similar effect of flattening the likelihood landscape. We further explore directly regularizing towards a flat landscape for adversarial robustness."
}
